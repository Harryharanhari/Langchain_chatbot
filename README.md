# ğŸ“„ PDF Context-Aware Chatbot (RAG)  
### Built with LangChain, Streamlit, and Cloud LLMs

A context-aware PDF chatbot that allows users to upload documents and ask questions based strictly on the content of the uploaded file.

This project demonstrates a lightweight Retrieval-Augmented Generation (RAG) pipeline using modern LLM tooling and a simple, deployable Streamlit interface.

---

## ğŸš€ Features

- ğŸ“‚ Upload any PDF document  
- ğŸ” Automatic text extraction and chunking  
- ğŸ§  Context-based question answering  
- â˜ï¸ Cloud LLM integration (Groq API)  
- ğŸ’¬ Interactive chat interface  
- ğŸ”’ Privacy-friendly (no data storage)

---

## ğŸ§  How It Works

This project follows a simple RAG workflow:

1. **PDF Upload**  
   - User uploads a document  
   - Text is extracted using PyPDFLoader  

2. **Text Chunking**  
   - Document split into smaller chunks  
   - Improves retrieval accuracy  

3. **Context Retrieval**  
   - Relevant chunks selected using keyword scoring  

4. **LLM Response**  
   - Context + question sent to cloud LLM  
   - Model answers only from document context  

---

## ğŸ›  Tech Stack

- **LangChain** â€“ LLM orchestration  
- **Streamlit** â€“ Web interface  
- **Groq API** â€“ High-speed cloud LLM  
- **PyPDF** â€“ PDF processing  

---

## ğŸ“¦ Installation

### 1. Clone Repository
```bash
git clone <repo-url>
cd <folder>
